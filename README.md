# Exploratory Data Analysis Using Python
 Data Analysis Using Web Scraping For Automobiles
 
 In this project I'm trying to analyze and visualize the used Web Scraping data set

# I'm planning to divide it in four parts:

     # Data Extraction(web Scraping)
     # Data PreProcessing(Numpy,Pandas)
     # Data Cleaning and Data Wrangling
     # Data Visualisation(Matplotlib,Seaborn)

# Description

 This data set consists of three types of entities:
    (a) the specification of an auto in terms of various characteristics,(b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars. The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process "symboling". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.

The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.


# Conclusion

 Analysis of the data set provides:

    # How the data set are distributed
    # Correlation between different fields and how they are related
    # Normalized loss of the manufacturer
    # Symboling : Cars are initially assigned a risk factor symbol associated with its price
    # Mileage : Mileage based on City and Highway driving for various make and attributes
    # Price : Factors affecting Price of the Automobile.
    # Importance of drive wheels and curb weight
